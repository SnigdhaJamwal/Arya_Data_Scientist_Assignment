{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arya.ai Assignment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjRnOOfkwG8TdZtvdfa3yq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SnigdhaJamwal/Arya_Data_Scientist_Assignment/blob/main/Arya_ai_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UtP59lyTJAY7"
      },
      "outputs": [],
      "source": [
        "# import all the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split  \n",
        "from sklearn.feature_selection import SelectKBest, chi2, RFE, SelectFromModel\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from keras import layers, models, optimizers, losses, regularizers, metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "KfX3dXzle-I2",
        "outputId": "f85448a0-03c1-4896-f50f-eee2ca3e4c6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0de6a45e-21f7-45e3-baf7-67e56d25fe36\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0de6a45e-21f7-45e3-baf7-67e56d25fe36\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_set.csv to test_set.csv\n",
            "Saving training_set.csv to training_set.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/\""
      ],
      "metadata": {
        "id": "2NvbBpl8ZYjm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = pd.read_csv(path + \"training_set.csv\")\n",
        "test_data = pd.read_csv(path + \"test_set.csv\")"
      ],
      "metadata": {
        "id": "BwsCs3WWZC5k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the input and output variables\n",
        "X = training_data.iloc[:, 1:-1]\n",
        "y = training_data.iloc[:, -1]\n",
        "X.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "NIPHsGjO4cdM",
        "outputId": "43b3f192-438c-4bdf-cb6f-f0bf796f4950"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                X1           X2           X3           X4           X5  \\\n",
              "count  3910.000000  3910.000000  3910.000000  3910.000000  3910.000000   \n",
              "mean      0.102990     0.206419     0.284419     0.062074     0.311309   \n",
              "std       0.296322     1.253828     0.504352     1.369361     0.656195   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.430000     0.000000     0.387500   \n",
              "max       4.340000    14.280000     4.540000    42.810000     9.090000   \n",
              "\n",
              "                X6           X7           X8           X9          X10  ...  \\\n",
              "count  3910.000000  3910.000000  3910.000000  3910.000000  3910.000000  ...   \n",
              "mean      0.095974     0.112320     0.106041     0.091146     0.244345  ...   \n",
              "std       0.261455     0.389516     0.398694     0.271417     0.667065  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.170000  ...   \n",
              "max       3.570000     7.270000    11.110000     3.230000    18.180000  ...   \n",
              "\n",
              "               X48          X49          X50          X51          X52  \\\n",
              "count  3910.000000  3910.000000  3910.000000  3910.000000  3910.000000   \n",
              "mean      0.033281     0.037493     0.139252     0.015876     0.272971   \n",
              "std       0.301611     0.235054     0.276309     0.083600     0.858634   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.066000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.188000     0.000000     0.317250   \n",
              "max      10.000000     4.385000     9.752000     2.777000    32.478000   \n",
              "\n",
              "               X53          X54          X55          X56           X57  \n",
              "count  3910.000000  3910.000000  3910.000000  3910.000000   3910.000000  \n",
              "mean      0.077820     0.043828     5.047150    52.338107    283.059079  \n",
              "std       0.256991     0.452862    31.397035   204.445218    578.339858  \n",
              "min       0.000000     0.000000     1.000000     1.000000      1.000000  \n",
              "25%       0.000000     0.000000     1.580750     6.000000     35.000000  \n",
              "50%       0.000000     0.000000     2.263500    15.000000     94.000000  \n",
              "75%       0.054000     0.000000     3.714000    43.000000    264.000000  \n",
              "max       6.003000    19.829000  1102.500000  9989.000000  10062.000000  \n",
              "\n",
              "[8 rows x 57 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-827bbfcb-f65e-4b56-9dfe-35a6c7fcd949\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>...</th>\n",
              "      <th>X48</th>\n",
              "      <th>X49</th>\n",
              "      <th>X50</th>\n",
              "      <th>X51</th>\n",
              "      <th>X52</th>\n",
              "      <th>X53</th>\n",
              "      <th>X54</th>\n",
              "      <th>X55</th>\n",
              "      <th>X56</th>\n",
              "      <th>X57</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "      <td>3910.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.102990</td>\n",
              "      <td>0.206419</td>\n",
              "      <td>0.284419</td>\n",
              "      <td>0.062074</td>\n",
              "      <td>0.311309</td>\n",
              "      <td>0.095974</td>\n",
              "      <td>0.112320</td>\n",
              "      <td>0.106041</td>\n",
              "      <td>0.091146</td>\n",
              "      <td>0.244345</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033281</td>\n",
              "      <td>0.037493</td>\n",
              "      <td>0.139252</td>\n",
              "      <td>0.015876</td>\n",
              "      <td>0.272971</td>\n",
              "      <td>0.077820</td>\n",
              "      <td>0.043828</td>\n",
              "      <td>5.047150</td>\n",
              "      <td>52.338107</td>\n",
              "      <td>283.059079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.296322</td>\n",
              "      <td>1.253828</td>\n",
              "      <td>0.504352</td>\n",
              "      <td>1.369361</td>\n",
              "      <td>0.656195</td>\n",
              "      <td>0.261455</td>\n",
              "      <td>0.389516</td>\n",
              "      <td>0.398694</td>\n",
              "      <td>0.271417</td>\n",
              "      <td>0.667065</td>\n",
              "      <td>...</td>\n",
              "      <td>0.301611</td>\n",
              "      <td>0.235054</td>\n",
              "      <td>0.276309</td>\n",
              "      <td>0.083600</td>\n",
              "      <td>0.858634</td>\n",
              "      <td>0.256991</td>\n",
              "      <td>0.452862</td>\n",
              "      <td>31.397035</td>\n",
              "      <td>204.445218</td>\n",
              "      <td>578.339858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.580750</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.263500</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>94.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.387500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.317250</td>\n",
              "      <td>0.054000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.714000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>264.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.340000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>4.540000</td>\n",
              "      <td>42.810000</td>\n",
              "      <td>9.090000</td>\n",
              "      <td>3.570000</td>\n",
              "      <td>7.270000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>3.230000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>...</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.385000</td>\n",
              "      <td>9.752000</td>\n",
              "      <td>2.777000</td>\n",
              "      <td>32.478000</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.829000</td>\n",
              "      <td>1102.500000</td>\n",
              "      <td>9989.000000</td>\n",
              "      <td>10062.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 57 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-827bbfcb-f65e-4b56-9dfe-35a6c7fcd949')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-827bbfcb-f65e-4b56-9dfe-35a6c7fcd949 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-827bbfcb-f65e-4b56-9dfe-35a6c7fcd949');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the missing values in input\n",
        "X.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZVRJt6ezTaY",
        "outputId": "6c53b6f9-0a7b-4529-c0d2-a9e1ba975a45"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "X1     0\n",
              "X2     0\n",
              "X3     0\n",
              "X4     0\n",
              "X5     0\n",
              "X6     0\n",
              "X7     0\n",
              "X8     0\n",
              "X9     0\n",
              "X10    0\n",
              "X11    0\n",
              "X12    0\n",
              "X13    0\n",
              "X14    0\n",
              "X15    0\n",
              "X16    0\n",
              "X17    0\n",
              "X18    0\n",
              "X19    0\n",
              "X20    0\n",
              "X21    0\n",
              "X22    0\n",
              "X23    0\n",
              "X24    0\n",
              "X25    0\n",
              "X26    0\n",
              "X27    0\n",
              "X28    0\n",
              "X29    0\n",
              "X30    0\n",
              "X31    0\n",
              "X32    0\n",
              "X33    0\n",
              "X34    0\n",
              "X35    0\n",
              "X36    0\n",
              "X37    0\n",
              "X38    0\n",
              "X39    0\n",
              "X40    0\n",
              "X41    0\n",
              "X42    0\n",
              "X43    0\n",
              "X44    0\n",
              "X45    0\n",
              "X46    0\n",
              "X47    0\n",
              "X48    0\n",
              "X49    0\n",
              "X50    0\n",
              "X51    0\n",
              "X52    0\n",
              "X53    0\n",
              "X54    0\n",
              "X55    0\n",
              "X56    0\n",
              "X57    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the missing values in the output.\n",
        "y.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1B126UU5ln9",
        "outputId": "cc69f403-b6a9-495c-c1b3-e1f8e85ec25b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection"
      ],
      "metadata": {
        "id": "SGSQkLJwArih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_feats = 25"
      ],
      "metadata": {
        "id": "2pjZpNDlWlYj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Pearson Correlation"
      ],
      "metadata": {
        "id": "AG_ghZ0sBg8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cor_selector(X, y,num_feats):\n",
        "    cor_list = []\n",
        "    feature_name = X.columns.tolist()\n",
        "    # calculate the correlation with y for each feature\n",
        "    for i in X.columns.tolist():\n",
        "        cor = np.corrcoef(X[i], y)[0, 1]\n",
        "        cor_list.append(cor)\n",
        "    # replace NaN with 0\n",
        "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
        "    # feature name\n",
        "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
        "    # feature selection? 0 for not select, 1 for select\n",
        "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
        "    return cor_support, cor_feature\n",
        "cor_support, cor_feature = cor_selector(X, y,num_feats)\n",
        "print(str(len(cor_feature)), 'selected features')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0L7ESthAumz",
        "outputId": "f5b00391-3383-4f1f-d983-cdc093bca0ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25 selected features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Chi-squared"
      ],
      "metadata": {
        "id": "SqhzAdyoBnJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_norm = MinMaxScaler().fit_transform(X)\n",
        "chi_selector = SelectKBest(chi2, k=num_feats)\n",
        "chi_selector.fit(X_norm, y)\n",
        "chi_support = chi_selector.get_support()\n",
        "chi_feature = X.loc[:,chi_support].columns.tolist()\n",
        "print(str(len(chi_feature)), 'selected features')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HqQXKl5A5Qp",
        "outputId": "d9420767-484c-4843-90bc-c9fac0e7bdbf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25 selected features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Recursive Feature Elimination"
      ],
      "metadata": {
        "id": "PyjRe-WvB0Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=num_feats, step=10, verbose=5)\n",
        "rfe_selector.fit(X_norm, y)\n",
        "rfe_support = rfe_selector.get_support()\n",
        "rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
        "print(str(len(rfe_feature)), 'selected features')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z880_jsIBQ9O",
        "outputId": "bab35d26-5092-445e-a963-c6481fc5128d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting estimator with 57 features.\n",
            "Fitting estimator with 47 features.\n",
            "Fitting estimator with 37 features.\n",
            "Fitting estimator with 27 features.\n",
            "25 selected features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4. Lasso"
      ],
      "metadata": {
        "id": "6RFSkmAiCI8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l2\"), max_features=num_feats)\n",
        "embeded_lr_selector.fit(X_norm, y)\n",
        "\n",
        "embeded_lr_support = embeded_lr_selector.get_support()\n",
        "embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
        "print(str(len(embeded_lr_feature)), 'selected features')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwfEZNNAB_Of",
        "outputId": "d4fc6d31-90e6-4920-808b-19150e371f85"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 selected features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 5. Tree-based: SelectFromModel"
      ],
      "metadata": {
        "id": "s7Z27rWiChcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=num_feats)\n",
        "embeded_rf_selector.fit(X, y)\n",
        "\n",
        "embeded_rf_support = embeded_rf_selector.get_support()\n",
        "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
        "print(str(len(embeded_rf_feature)), 'selected features')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W_p5YqBCcrd",
        "outputId": "36a5ffdf-7b58-452f-9bdf-4a08cca05581"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 selected features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_name = X.columns.tolist()\n",
        "# put all selection together\n",
        "feature_selection_df = pd.DataFrame({'Feature': feature_name, 'Pearson':cor_support, 'Chi-2':chi_support, 'RFE':rfe_support, 'Logistics':embeded_lr_support, 'Random Forest':embeded_rf_support})\n",
        "# count the selected times for each feature\n",
        "feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
        "# display the top 100\n",
        "feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
        "feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
        "feature_selection_df.head(num_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "id": "pwicU8wTApvV",
        "outputId": "e93a43ed-7f72-4bb6-d0b7-07afa418373d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:84: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Feature  Pearson  Chi-2    RFE  Logistics  Random Forest  Total\n",
              "1       X7     True   True   True       True           True      5\n",
              "2      X57     True   True   True       True           True      5\n",
              "3      X53     True   True   True       True           True      5\n",
              "4       X5     True   True   True       True           True      5\n",
              "5      X27     True   True   True       True           True      5\n",
              "6      X25     True   True   True       True           True      5\n",
              "7      X24     True   True   True       True           True      5\n",
              "8      X23     True   True   True       True           True      5\n",
              "9      X21     True   True   True       True           True      5\n",
              "10     X16     True   True   True       True           True      5\n",
              "11      X9     True   True   True       True          False      4\n",
              "12      X8     True   True   True       True          False      4\n",
              "13      X6     True   True   True       True          False      4\n",
              "14     X52     True  False   True       True           True      4\n",
              "15     X26     True   True   True       True          False      4\n",
              "16     X20     True   True   True       True          False      4\n",
              "17     X19     True   True   True      False           True      4\n",
              "18     X18     True   True   True       True          False      4\n",
              "19     X17     True   True   True       True          False      4\n",
              "20     X37     True   True   True      False          False      3\n",
              "21     X30     True   True   True      False          False      3\n",
              "22     X56     True  False  False      False           True      2\n",
              "23     X46    False  False   True       True          False      2\n",
              "24     X45    False  False   True       True          False      2\n",
              "25     X42    False  False   True       True          False      2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4969714a-bfb8-4220-8d3d-cd1124e2da43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Pearson</th>\n",
              "      <th>Chi-2</th>\n",
              "      <th>RFE</th>\n",
              "      <th>Logistics</th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>X7</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>X57</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>X53</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>X5</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>X27</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>X25</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>X24</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>X23</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>X21</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>X16</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>X9</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>X8</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>X6</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>X52</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>X26</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>X20</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>X19</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>X18</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>X17</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>X37</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>X30</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>X56</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>X46</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>X45</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>X42</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4969714a-bfb8-4220-8d3d-cd1124e2da43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4969714a-bfb8-4220-8d3d-cd1124e2da43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4969714a-bfb8-4220-8d3d-cd1124e2da43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(feature_selection_df['Feature'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq0ToRTuQ08w",
        "outputId": "6e66dec2-c02c-4509-c41e-fc58551516d7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_X = pd.DataFrame(X,columns = feature_selection_df['Feature'][:25].tolist())"
      ],
      "metadata": {
        "id": "xoUhwsOUP4bL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(reduced_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2_ixLtZRFf1",
        "outputId": "b890e783-c0b8-45e4-ee0b-1318ffde0069"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        X7  X57    X53    X5  X27    X25   X24   X23   X21   X16  ...  X20  \\\n",
            "0     0.00   12  0.000  0.00  0.0   0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
            "1     2.25  375  0.000  1.12  0.0   0.00  0.00  0.00  1.12  0.00  ...  0.0   \n",
            "2     0.00    5  0.000  0.00  0.0   0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
            "3     0.00  122  0.370  1.93  0.0   0.00  0.00  0.64  2.58  1.29  ...  0.0   \n",
            "4     0.58  207  0.239  0.58  0.0   0.00  1.16  0.00  1.74  0.58  ...  0.0   \n",
            "...    ...  ...    ...   ...  ...    ...   ...   ...   ...   ...  ...  ...   \n",
            "3905  0.00   12  0.000  0.00  0.0   0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
            "3906  0.00    4  0.000  0.00  0.0  18.18  0.00  0.00  0.00  0.00  ...  0.0   \n",
            "3907  0.00  131  0.000  0.00  0.0   0.00  0.00  0.00  0.51  0.12  ...  0.0   \n",
            "3908  0.00   81  0.198  0.00  0.0   0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
            "3909  0.00  717  0.467  0.00  0.0   0.00  0.48  0.00  0.96  0.48  ...  0.0   \n",
            "\n",
            "       X19   X18   X17  X37  X30  X56   X46   X45  X42  \n",
            "0     0.00  0.00  0.00  0.0  0.0    2  0.00  0.00  0.0  \n",
            "1     3.38  0.56  0.00  0.0  0.0  148  0.00  0.56  0.0  \n",
            "2     8.10  0.00  0.00  0.0  0.0    1  0.00  2.70  0.0  \n",
            "3     1.93  0.00  0.64  0.0  0.0   22  0.00  0.00  0.0  \n",
            "4     0.58  0.58  0.58  0.0  0.0  123  0.00  0.00  0.0  \n",
            "...    ...   ...   ...  ...  ...  ...   ...   ...  ...  \n",
            "3905  7.31  0.00  0.00  0.0  0.0    4  0.00  0.00  0.0  \n",
            "3906  0.00  0.00  0.00  0.0  0.0    3  0.00  0.00  0.0  \n",
            "3907  2.19  0.00  0.00  0.0  0.0    5  0.12  0.25  0.0  \n",
            "3908  0.00  0.00  0.00  0.0  0.0   25  0.00  1.04  0.0  \n",
            "3909  0.00  2.41  0.48  0.0  0.0  259  0.48  0.00  0.0  \n",
            "\n",
            "[3910 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset in the ration 4:1\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
      ],
      "metadata": {
        "id": "3nnhuZj2c29K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05258be8-aa3b-4b76-c26c-9d125a3a2057"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3519, 57) (391, 57) (3519,) (391,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split the reduced dataset in the ratio 4:1\n",
        "X_reduced_train, X_reduced_val, y_reduced_train, y_reduced_val = train_test_split(reduced_X , y, test_size=0.1, random_state=0)\n",
        "print(X_reduced_train.shape, X_reduced_val.shape, y_reduced_train.shape, y_reduced_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbFEqMRx5Yu4",
        "outputId": "7ad45e2d-e9be-481d-ea15-774878dbad57"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3519, 25) (391, 25) (3519,) (391,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and testing different algorithms\n",
        "\n"
      ],
      "metadata": {
        "id": "cu2u5mBK5LNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Naive Bayes"
      ],
      "metadata": {
        "id": "xvH5b3Ts5gRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnb = MultinomialNB().fit(X_train, y_train)\n",
        "print(\"score on test: \" + str(mnb.score(X_val, y_val)))\n",
        "print(\"score on train: \"+ str(mnb.score(X_train, y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUI_PsMx5fl3",
        "outputId": "7ba4c782-2dce-4d07-958e-6ba571f1b14d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score on test: 0.7877237851662404\n",
            "score on train: 0.7945439045183291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_mnb = MultinomialNB().fit(X_reduced_train, y_reduced_train)\n",
        "print(\"score on test: \" + str(reduced_mnb.score(X_reduced_val, y_reduced_val)))\n",
        "print(\"score on train: \"+ str(reduced_mnb.score(X_reduced_train, y_reduced_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1X4RI7OSbOc",
        "outputId": "4bde15d0-5bb1-43b8-d7d0-fa7d7ceb1bc1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score on test: 0.7416879795396419\n",
            "score on train: 0.7601591361182154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Logistic Regression "
      ],
      "metadata": {
        "id": "GpgApnUC_wr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr=LogisticRegression(max_iter=2000)\n",
        "lr.fit(X_train, y_train)\n",
        "print(\"score on test: \" + str(lr.score(X_val, y_val)))\n",
        "print(\"score on train: \"+ str(lr.score(X_train, y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnqU-eZT1rpO",
        "outputId": "f6ab8ce9-1536-4be4-b69f-9a0c4611e5af"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score on test: 0.9360613810741688\n",
            "score on train: 0.9306621199204319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_lr=LogisticRegression(max_iter=2000)\n",
        "reduced_lr.fit(X_reduced_train, y_reduced_train)\n",
        "print(\"score on test: \" + str(reduced_lr.score(X_reduced_val, y_reduced_val)))\n",
        "print(\"score on train: \"+ str(reduced_lr.score(X_reduced_train, y_reduced_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtERDCYOSpJQ",
        "outputId": "bb097255-c056-4b5a-f40e-f8eab5fe9c22"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score on test: 0.9360613810741688\n",
            "score on train: 0.9195794259732879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Decision Tree (Overfitting)"
      ],
      "metadata": {
        "id": "7u3FuhRB_5vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"score on test: \"  + str(clf.score(X_val, y_val)))\n",
        "print(\"score on train: \" + str(clf.score(X_train, y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRtSRam3_abX",
        "outputId": "974e6a24-21f4-4474-b7cb-1c352f3f2e8a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score on test: 0.887468030690537\n",
            "score on train: 0.9997158283603297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_clf = DecisionTreeClassifier()\n",
        "reduced_clf.fit(X_reduced_train, y_reduced_train)\n",
        "print(\"score on test: \"  + str(reduced_clf.score(X_reduced_val, y_reduced_val)))\n",
        "print(\"score on train: \" + str(reduced_clf.score(X_reduced_train, y_reduced_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_zNH7YWTjNB",
        "outputId": "6535b566-3214-40bb-e9cc-13e562573e35"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score on test: 0.8900255754475703\n",
            "score on train: 0.9994316567206593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Neural Network"
      ],
      "metadata": {
        "id": "XseX_4uMTwA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=models.Sequential()\n",
        "model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.003),activation='relu',input_shape=(57,)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.003),activation='relu'))\n",
        "model.add(layers.Dropout(0.6))\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,epochs=250,batch_size=512)\n",
        "print(\"score on test: \" + str(model.evaluate(X_val,y_val)[1]))\n",
        "print(\"score on train: \"+ str(model.evaluate(X_train,y_train)[1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbQ8H4AFAxY_",
        "outputId": "35703baf-36be-4dbd-b0c6-6964ebc7be08"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 31.4992 - accuracy: 0.5323\n",
            "Epoch 2/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 28.9241 - accuracy: 0.5297\n",
            "Epoch 3/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 23.5658 - accuracy: 0.5377\n",
            "Epoch 4/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 25.3456 - accuracy: 0.5413\n",
            "Epoch 5/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 24.1050 - accuracy: 0.5439\n",
            "Epoch 6/250\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 24.1464 - accuracy: 0.5431\n",
            "Epoch 7/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 18.3338 - accuracy: 0.5399\n",
            "Epoch 8/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 18.5613 - accuracy: 0.5536\n",
            "Epoch 9/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 18.1529 - accuracy: 0.5499\n",
            "Epoch 10/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 17.8843 - accuracy: 0.5368\n",
            "Epoch 11/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 15.5222 - accuracy: 0.5536\n",
            "Epoch 12/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 14.9688 - accuracy: 0.5601\n",
            "Epoch 13/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 14.5523 - accuracy: 0.5453\n",
            "Epoch 14/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 13.2725 - accuracy: 0.5664\n",
            "Epoch 15/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 12.5632 - accuracy: 0.5485\n",
            "Epoch 16/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 10.8998 - accuracy: 0.5686\n",
            "Epoch 17/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 10.6547 - accuracy: 0.5621\n",
            "Epoch 18/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 8.7687 - accuracy: 0.5834\n",
            "Epoch 19/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 10.0413 - accuracy: 0.5797\n",
            "Epoch 20/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 7.1204 - accuracy: 0.5700\n",
            "Epoch 21/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 6.4187 - accuracy: 0.5990\n",
            "Epoch 22/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 5.4279 - accuracy: 0.5931\n",
            "Epoch 23/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.6305 - accuracy: 0.6007\n",
            "Epoch 24/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.6070 - accuracy: 0.6030\n",
            "Epoch 25/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8809 - accuracy: 0.6039\n",
            "Epoch 26/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.2112 - accuracy: 0.6002\n",
            "Epoch 27/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.4132 - accuracy: 0.6229\n",
            "Epoch 28/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.2295 - accuracy: 0.6090\n",
            "Epoch 29/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.3353 - accuracy: 0.6334\n",
            "Epoch 30/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.5732 - accuracy: 0.6226\n",
            "Epoch 31/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.1725 - accuracy: 0.6178\n",
            "Epoch 32/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.6197 - accuracy: 0.6303\n",
            "Epoch 33/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.6565 - accuracy: 0.6402\n",
            "Epoch 34/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.6511 - accuracy: 0.6246\n",
            "Epoch 35/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.1863 - accuracy: 0.6246\n",
            "Epoch 36/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.1788 - accuracy: 0.6206\n",
            "Epoch 37/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.0306 - accuracy: 0.6314\n",
            "Epoch 38/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.0120 - accuracy: 0.6388\n",
            "Epoch 39/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.9134 - accuracy: 0.6394\n",
            "Epoch 40/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8655 - accuracy: 0.6363\n",
            "Epoch 41/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7910 - accuracy: 0.6351\n",
            "Epoch 42/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7239 - accuracy: 0.6329\n",
            "Epoch 43/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.6326\n",
            "Epoch 44/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7020 - accuracy: 0.6243\n",
            "Epoch 45/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.6252\n",
            "Epoch 46/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.6201\n",
            "Epoch 47/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.6198\n",
            "Epoch 48/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.6206\n",
            "Epoch 49/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6161\n",
            "Epoch 50/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.6184\n",
            "Epoch 51/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.6152\n",
            "Epoch 52/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6172\n",
            "Epoch 53/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6181\n",
            "Epoch 54/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.6186\n",
            "Epoch 55/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6169\n",
            "Epoch 56/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6167\n",
            "Epoch 57/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.6184\n",
            "Epoch 58/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.6132\n",
            "Epoch 59/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6238\n",
            "Epoch 60/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.6201\n",
            "Epoch 61/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.6206\n",
            "Epoch 62/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.6275\n",
            "Epoch 63/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.6348\n",
            "Epoch 64/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.6374\n",
            "Epoch 65/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.6331\n",
            "Epoch 66/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.6445\n",
            "Epoch 67/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.6465\n",
            "Epoch 68/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.6590\n",
            "Epoch 69/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.6809\n",
            "Epoch 70/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.6837\n",
            "Epoch 71/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.6903\n",
            "Epoch 72/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.6922\n",
            "Epoch 73/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.6988\n",
            "Epoch 74/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.6976\n",
            "Epoch 75/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7036\n",
            "Epoch 76/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7090\n",
            "Epoch 77/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7283\n",
            "Epoch 78/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7315\n",
            "Epoch 79/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7172\n",
            "Epoch 80/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7363\n",
            "Epoch 81/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7269\n",
            "Epoch 82/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7224\n",
            "Epoch 83/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7366\n",
            "Epoch 84/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7425\n",
            "Epoch 85/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7326\n",
            "Epoch 86/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7420\n",
            "Epoch 87/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7383\n",
            "Epoch 88/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7542\n",
            "Epoch 89/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7454\n",
            "Epoch 90/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7445\n",
            "Epoch 91/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7511\n",
            "Epoch 92/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7408\n",
            "Epoch 93/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7553\n",
            "Epoch 94/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7511\n",
            "Epoch 95/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7479\n",
            "Epoch 96/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7585\n",
            "Epoch 97/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7468\n",
            "Epoch 98/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7496\n",
            "Epoch 99/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7562\n",
            "Epoch 100/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7499\n",
            "Epoch 101/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7567\n",
            "Epoch 102/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7610\n",
            "Epoch 103/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7505\n",
            "Epoch 104/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7562\n",
            "Epoch 105/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7656\n",
            "Epoch 106/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7556\n",
            "Epoch 107/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7562\n",
            "Epoch 108/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7607\n",
            "Epoch 109/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7516\n",
            "Epoch 110/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7664\n",
            "Epoch 111/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7613\n",
            "Epoch 112/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7658\n",
            "Epoch 113/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7550\n",
            "Epoch 114/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7641\n",
            "Epoch 115/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7562\n",
            "Epoch 116/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7644\n",
            "Epoch 117/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7653\n",
            "Epoch 118/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7567\n",
            "Epoch 119/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7656\n",
            "Epoch 120/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7579\n",
            "Epoch 121/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7732\n",
            "Epoch 122/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7792\n",
            "Epoch 123/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8377\n",
            "Epoch 124/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8272\n",
            "Epoch 125/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8284\n",
            "Epoch 126/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8338\n",
            "Epoch 127/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8474\n",
            "Epoch 128/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8440\n",
            "Epoch 129/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.8352\n",
            "Epoch 130/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8463\n",
            "Epoch 131/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8346\n",
            "Epoch 132/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8357\n",
            "Epoch 133/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8485\n",
            "Epoch 134/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8491\n",
            "Epoch 135/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8338\n",
            "Epoch 136/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8465\n",
            "Epoch 137/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8525\n",
            "Epoch 138/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8443\n",
            "Epoch 139/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8562\n",
            "Epoch 140/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8426\n",
            "Epoch 141/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8298\n",
            "Epoch 142/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8448\n",
            "Epoch 143/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8474\n",
            "Epoch 144/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8585\n",
            "Epoch 145/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.8372\n",
            "Epoch 146/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8548\n",
            "Epoch 147/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8448\n",
            "Epoch 148/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8508\n",
            "Epoch 149/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8576\n",
            "Epoch 150/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8562\n",
            "Epoch 151/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8414\n",
            "Epoch 152/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8565\n",
            "Epoch 153/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8477\n",
            "Epoch 154/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8522\n",
            "Epoch 155/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8468\n",
            "Epoch 156/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8599\n",
            "Epoch 157/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8517\n",
            "Epoch 158/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8605\n",
            "Epoch 159/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8511\n",
            "Epoch 160/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8636\n",
            "Epoch 161/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8537\n",
            "Epoch 162/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8511\n",
            "Epoch 163/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8551\n",
            "Epoch 164/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8554\n",
            "Epoch 165/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8565\n",
            "Epoch 166/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8539\n",
            "Epoch 167/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.8591\n",
            "Epoch 168/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8559\n",
            "Epoch 169/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8625\n",
            "Epoch 170/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8508\n",
            "Epoch 171/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8448\n",
            "Epoch 172/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8653\n",
            "Epoch 173/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8619\n",
            "Epoch 174/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8488\n",
            "Epoch 175/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8502\n",
            "Epoch 176/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8565\n",
            "Epoch 177/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8556\n",
            "Epoch 178/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8528\n",
            "Epoch 179/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8613\n",
            "Epoch 180/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8616\n",
            "Epoch 181/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8542\n",
            "Epoch 182/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8571\n",
            "Epoch 183/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8519\n",
            "Epoch 184/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8508\n",
            "Epoch 185/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8537\n",
            "Epoch 186/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8537\n",
            "Epoch 187/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3898 - accuracy: 0.8565\n",
            "Epoch 188/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8573\n",
            "Epoch 189/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8559\n",
            "Epoch 190/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8681\n",
            "Epoch 191/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8627\n",
            "Epoch 192/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8505\n",
            "Epoch 193/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8636\n",
            "Epoch 194/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8551\n",
            "Epoch 195/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8599\n",
            "Epoch 196/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8681\n",
            "Epoch 197/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8429\n",
            "Epoch 198/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8497\n",
            "Epoch 199/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8554\n",
            "Epoch 200/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8619\n",
            "Epoch 201/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3717 - accuracy: 0.8625\n",
            "Epoch 202/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8573\n",
            "Epoch 203/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8346\n",
            "Epoch 204/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8477\n",
            "Epoch 205/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3684 - accuracy: 0.8630\n",
            "Epoch 206/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8627\n",
            "Epoch 207/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8613\n",
            "Epoch 208/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8548\n",
            "Epoch 209/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8500\n",
            "Epoch 210/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8522\n",
            "Epoch 211/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8656\n",
            "Epoch 212/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8645\n",
            "Epoch 213/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8690\n",
            "Epoch 214/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8673\n",
            "Epoch 215/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8681\n",
            "Epoch 216/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8656\n",
            "Epoch 217/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8653\n",
            "Epoch 218/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8619\n",
            "Epoch 219/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8483\n",
            "Epoch 220/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8639\n",
            "Epoch 221/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8639\n",
            "Epoch 222/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8451\n",
            "Epoch 223/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8684\n",
            "Epoch 224/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8602\n",
            "Epoch 225/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8440\n",
            "Epoch 226/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.8551\n",
            "Epoch 227/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3686 - accuracy: 0.8645\n",
            "Epoch 228/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8545\n",
            "Epoch 229/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8559\n",
            "Epoch 230/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8505\n",
            "Epoch 231/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8622\n",
            "Epoch 232/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8528\n",
            "Epoch 233/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8633\n",
            "Epoch 234/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8630\n",
            "Epoch 235/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8531\n",
            "Epoch 236/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8571\n",
            "Epoch 237/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8647\n",
            "Epoch 238/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8562\n",
            "Epoch 239/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8548\n",
            "Epoch 240/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8625\n",
            "Epoch 241/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8718\n",
            "Epoch 242/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.8645\n",
            "Epoch 243/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8605\n",
            "Epoch 244/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8539\n",
            "Epoch 245/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8551\n",
            "Epoch 246/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8485\n",
            "Epoch 247/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8676\n",
            "Epoch 248/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8616\n",
            "Epoch 249/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8633\n",
            "Epoch 250/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8522\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.9105\n",
            "score on test: 0.9104859232902527\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8860\n",
            "score on train: 0.8860471844673157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_model=models.Sequential()\n",
        "reduced_model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.003),activation='relu',input_shape=(25,)))\n",
        "reduced_model.add(layers.Dropout(0.5))\n",
        "reduced_model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.003),activation='relu'))\n",
        "reduced_model.add(layers.Dropout(0.6))\n",
        "reduced_model.add(layers.Dense(1,activation='sigmoid'))\n",
        "reduced_model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "reduced_model.fit(X_reduced_train,y_reduced_train,epochs=250,batch_size=512)\n",
        "print(\"score on test: \" + str(reduced_model.evaluate(X_reduced_val,y_reduced_val)[1]))\n",
        "print(\"score on train: \"+ str(reduced_model.evaluate(X_reduced_train,y_reduced_train)[1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkvMbFNgF0pQ",
        "outputId": "c6b6b53d-5dd9-41f5-b3b0-33411bcccbd9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 17.2034 - accuracy: 0.5220\n",
            "Epoch 2/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 16.0016 - accuracy: 0.5365\n",
            "Epoch 3/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 13.6512 - accuracy: 0.5470\n",
            "Epoch 4/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 16.8327 - accuracy: 0.5442\n",
            "Epoch 5/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 11.8475 - accuracy: 0.5561\n",
            "Epoch 6/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 12.8970 - accuracy: 0.5459\n",
            "Epoch 7/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 10.5208 - accuracy: 0.5578\n",
            "Epoch 8/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 9.9519 - accuracy: 0.5578\n",
            "Epoch 9/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 8.8580 - accuracy: 0.5544\n",
            "Epoch 10/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 8.1634 - accuracy: 0.5772\n",
            "Epoch 11/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 7.1295 - accuracy: 0.5644\n",
            "Epoch 12/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 6.5424 - accuracy: 0.5635\n",
            "Epoch 13/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 5.5021 - accuracy: 0.5851\n",
            "Epoch 14/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 5.9919 - accuracy: 0.5783\n",
            "Epoch 15/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 5.2571 - accuracy: 0.5695\n",
            "Epoch 16/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 5.2763 - accuracy: 0.5800\n",
            "Epoch 17/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7423 - accuracy: 0.5874\n",
            "Epoch 18/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.2511 - accuracy: 0.5791\n",
            "Epoch 19/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.7452 - accuracy: 0.5840\n",
            "Epoch 20/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1742 - accuracy: 0.5862\n",
            "Epoch 21/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2017 - accuracy: 0.5965\n",
            "Epoch 22/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2387 - accuracy: 0.5894\n",
            "Epoch 23/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.6501 - accuracy: 0.5982\n",
            "Epoch 24/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.5848 - accuracy: 0.5973\n",
            "Epoch 25/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.7239 - accuracy: 0.5899\n",
            "Epoch 26/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.8492 - accuracy: 0.5862\n",
            "Epoch 27/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.3972 - accuracy: 0.5973\n",
            "Epoch 28/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.7460 - accuracy: 0.6019\n",
            "Epoch 29/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.2975 - accuracy: 0.5871\n",
            "Epoch 30/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.9418 - accuracy: 0.5979\n",
            "Epoch 31/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.0529 - accuracy: 0.5999\n",
            "Epoch 32/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.6749 - accuracy: 0.5968\n",
            "Epoch 33/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.7866 - accuracy: 0.5948\n",
            "Epoch 34/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.6423 - accuracy: 0.6027\n",
            "Epoch 35/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.4638 - accuracy: 0.5956\n",
            "Epoch 36/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.6720 - accuracy: 0.6027\n",
            "Epoch 37/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.3820 - accuracy: 0.6002\n",
            "Epoch 38/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.3456 - accuracy: 0.5999\n",
            "Epoch 39/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.1063 - accuracy: 0.6047\n",
            "Epoch 40/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.0806 - accuracy: 0.5919\n",
            "Epoch 41/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.0033 - accuracy: 0.5999\n",
            "Epoch 42/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.1316 - accuracy: 0.5942\n",
            "Epoch 43/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.9832 - accuracy: 0.6039\n",
            "Epoch 44/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.9208 - accuracy: 0.6053\n",
            "Epoch 45/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.8935 - accuracy: 0.6027\n",
            "Epoch 46/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.0810 - accuracy: 0.5996\n",
            "Epoch 47/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8381 - accuracy: 0.6044\n",
            "Epoch 48/250\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.8267 - accuracy: 0.6044\n",
            "Epoch 49/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7980 - accuracy: 0.6053\n",
            "Epoch 50/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.8496 - accuracy: 0.6044\n",
            "Epoch 51/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7718 - accuracy: 0.6095\n",
            "Epoch 52/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8289 - accuracy: 0.6059\n",
            "Epoch 53/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.6101\n",
            "Epoch 54/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7640 - accuracy: 0.6027\n",
            "Epoch 55/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7203 - accuracy: 0.6053\n",
            "Epoch 56/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7591 - accuracy: 0.6019\n",
            "Epoch 57/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7637 - accuracy: 0.6047\n",
            "Epoch 58/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7566 - accuracy: 0.6050\n",
            "Epoch 59/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.6033\n",
            "Epoch 60/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7109 - accuracy: 0.6041\n",
            "Epoch 61/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.6030\n",
            "Epoch 62/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7017 - accuracy: 0.6070\n",
            "Epoch 63/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7056 - accuracy: 0.6033\n",
            "Epoch 64/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.6047\n",
            "Epoch 65/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7053 - accuracy: 0.6041\n",
            "Epoch 66/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.6044\n",
            "Epoch 67/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.6050\n",
            "Epoch 68/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.6036\n",
            "Epoch 69/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.6053\n",
            "Epoch 70/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.6050\n",
            "Epoch 71/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.6047\n",
            "Epoch 72/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.6050\n",
            "Epoch 73/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.6059\n",
            "Epoch 74/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.6061\n",
            "Epoch 75/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.6050\n",
            "Epoch 76/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.6056\n",
            "Epoch 77/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6776 - accuracy: 0.6053\n",
            "Epoch 78/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6782 - accuracy: 0.6050\n",
            "Epoch 79/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.6059\n",
            "Epoch 80/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.6056\n",
            "Epoch 81/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.6056\n",
            "Epoch 82/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.6056\n",
            "Epoch 83/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.6050\n",
            "Epoch 84/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6729 - accuracy: 0.6056\n",
            "Epoch 85/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.6056\n",
            "Epoch 86/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.6056\n",
            "Epoch 87/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.6059\n",
            "Epoch 88/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6050\n",
            "Epoch 89/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.6053\n",
            "Epoch 90/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.6059\n",
            "Epoch 91/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6056\n",
            "Epoch 92/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.6056\n",
            "Epoch 93/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6059\n",
            "Epoch 94/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6053\n",
            "Epoch 95/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6056\n",
            "Epoch 96/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.6056\n",
            "Epoch 97/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6056\n",
            "Epoch 98/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.6053\n",
            "Epoch 99/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.6059\n",
            "Epoch 100/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6056\n",
            "Epoch 101/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.6056\n",
            "Epoch 102/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.6059\n",
            "Epoch 103/250\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6667 - accuracy: 0.6059\n",
            "Epoch 104/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6059\n",
            "Epoch 105/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.6059\n",
            "Epoch 106/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.6059\n",
            "Epoch 107/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6059\n",
            "Epoch 108/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6059\n",
            "Epoch 109/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6056\n",
            "Epoch 110/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6059\n",
            "Epoch 111/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.6059\n",
            "Epoch 112/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6059\n",
            "Epoch 113/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.6059\n",
            "Epoch 114/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.6059\n",
            "Epoch 115/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.6059\n",
            "Epoch 116/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6059\n",
            "Epoch 117/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6104\n",
            "Epoch 118/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6218\n",
            "Epoch 119/250\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6340\n",
            "Epoch 120/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6326\n",
            "Epoch 121/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.6306\n",
            "Epoch 122/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6382\n",
            "Epoch 123/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6385\n",
            "Epoch 124/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.6357\n",
            "Epoch 125/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6329\n",
            "Epoch 126/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6382\n",
            "Epoch 127/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6371\n",
            "Epoch 128/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.6462\n",
            "Epoch 129/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.6573\n",
            "Epoch 130/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.6473\n",
            "Epoch 131/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.6542\n",
            "Epoch 132/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.6516\n",
            "Epoch 133/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.6689\n",
            "Epoch 134/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.6692\n",
            "Epoch 135/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.6729\n",
            "Epoch 136/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.6678\n",
            "Epoch 137/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.6743\n",
            "Epoch 138/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5655 - accuracy: 0.6735\n",
            "Epoch 139/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.6783\n",
            "Epoch 140/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.6743\n",
            "Epoch 141/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.6866\n",
            "Epoch 142/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.6769\n",
            "Epoch 143/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.6857\n",
            "Epoch 144/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.6846\n",
            "Epoch 145/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.6823\n",
            "Epoch 146/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.6746\n",
            "Epoch 147/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.6834\n",
            "Epoch 148/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7028\n",
            "Epoch 149/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.6843\n",
            "Epoch 150/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.6948\n",
            "Epoch 151/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.6857\n",
            "Epoch 152/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.6939\n",
            "Epoch 153/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.6897\n",
            "Epoch 154/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.6920\n",
            "Epoch 155/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.6954\n",
            "Epoch 156/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.6911\n",
            "Epoch 157/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.6979\n",
            "Epoch 158/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7008\n",
            "Epoch 159/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7025\n",
            "Epoch 160/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.6996\n",
            "Epoch 161/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7036\n",
            "Epoch 162/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.6991\n",
            "Epoch 163/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7025\n",
            "Epoch 164/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7008\n",
            "Epoch 165/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.6931\n",
            "Epoch 166/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.6988\n",
            "Epoch 167/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7062\n",
            "Epoch 168/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7011\n",
            "Epoch 169/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.6988\n",
            "Epoch 170/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7016\n",
            "Epoch 171/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7028\n",
            "Epoch 172/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.6996\n",
            "Epoch 173/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7042\n",
            "Epoch 174/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7062\n",
            "Epoch 175/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.6991\n",
            "Epoch 176/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7082\n",
            "Epoch 177/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7067\n",
            "Epoch 178/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7050\n",
            "Epoch 179/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7107\n",
            "Epoch 180/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7045\n",
            "Epoch 181/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7099\n",
            "Epoch 182/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7107\n",
            "Epoch 183/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7101\n",
            "Epoch 184/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7175\n",
            "Epoch 185/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.6991\n",
            "Epoch 186/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7070\n",
            "Epoch 187/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7039\n",
            "Epoch 188/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7099\n",
            "Epoch 189/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7070\n",
            "Epoch 190/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.6965\n",
            "Epoch 191/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7136\n",
            "Epoch 192/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7633\n",
            "Epoch 193/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7931\n",
            "Epoch 194/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8028\n",
            "Epoch 195/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7923\n",
            "Epoch 196/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7974\n",
            "Epoch 197/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8011\n",
            "Epoch 198/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8022\n",
            "Epoch 199/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.8014\n",
            "Epoch 200/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.8008\n",
            "Epoch 201/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7971\n",
            "Epoch 202/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7951\n",
            "Epoch 203/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7982\n",
            "Epoch 204/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.8011\n",
            "Epoch 205/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.8022\n",
            "Epoch 206/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.8008\n",
            "Epoch 207/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7835\n",
            "Epoch 208/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.8011\n",
            "Epoch 209/250\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.8068\n",
            "Epoch 210/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7971\n",
            "Epoch 211/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8119\n",
            "Epoch 212/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7968\n",
            "Epoch 213/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8124\n",
            "Epoch 214/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.8045\n",
            "Epoch 215/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8070\n",
            "Epoch 216/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8048\n",
            "Epoch 217/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7962\n",
            "Epoch 218/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.8096\n",
            "Epoch 219/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8062\n",
            "Epoch 220/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.8073\n",
            "Epoch 221/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.8070\n",
            "Epoch 222/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.8113\n",
            "Epoch 223/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.8053\n",
            "Epoch 224/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.8116\n",
            "Epoch 225/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.8159\n",
            "Epoch 226/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.8173\n",
            "Epoch 227/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.8093\n",
            "Epoch 228/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7994\n",
            "Epoch 229/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.8122\n",
            "Epoch 230/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.8105\n",
            "Epoch 231/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.8016\n",
            "Epoch 232/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8184\n",
            "Epoch 233/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.8230\n",
            "Epoch 234/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.8028\n",
            "Epoch 235/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.8073\n",
            "Epoch 236/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.8113\n",
            "Epoch 237/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.8127\n",
            "Epoch 238/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.8181\n",
            "Epoch 239/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.8184\n",
            "Epoch 240/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.8068\n",
            "Epoch 241/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.8124\n",
            "Epoch 242/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.8221\n",
            "Epoch 243/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.8016\n",
            "Epoch 244/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8028\n",
            "Epoch 245/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.8113\n",
            "Epoch 246/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.8213\n",
            "Epoch 247/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.8085\n",
            "Epoch 248/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.8204\n",
            "Epoch 249/250\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.8107\n",
            "Epoch 250/250\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.8124\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.9233\n",
            "score on test: 0.9232736825942993\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.9210\n",
            "score on train: 0.9210003018379211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final model: Logistic Regression model trained on the reduced dataset "
      ],
      "metadata": {
        "id": "BMV5-bYsU1WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_test_data = pd.DataFrame(test_data ,columns = feature_selection_df['Feature'][:25].tolist())\n",
        "test_pred = reduced_lr.predict(reduced_test_data)"
      ],
      "metadata": {
        "id": "zASy48EjVEmz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PK1cF_CfX_c",
        "outputId": "57a1e75d-c53b-49bd-88b3-607344b575d1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the test dataset predictions in a csv file\n",
        "pd.DataFrame(test_pred).to_csv('prediction.csv')"
      ],
      "metadata": {
        "id": "F90MFD5CW-fo"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GgWSfRIdfxhT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}